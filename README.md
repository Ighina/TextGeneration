# TextGeneration
Qui c'è la ricetta di base per addestrare un nuovo modello neurale di generazione di testo partendo da testi arbitrari.

## File .ipynb
Il repository contiene un'unico .ipynb file che può essere usato su jupyter notebook oppure (opzione consigliata) su Google Colab.
Seguire il notebook e cambiare unicamente l'assegnazione di input.txt (secondo il testo su cui addestrare il modello) per addestrare e testare il generatore neurale.

## Opzione consigliata: Google Colab
Per usare il notebook su google colab, aprire google colab (https://colab.research.google.com/?utm_source=scs-index) e scegliere l'opzione per importare il file .ipynb
(precedentemente scaricato in locale). Si consiglia di cambiare l'opzione del notebook così da includere il [GPU](https://www.google.com/search?rlz=1C1GCEA_enIT957IT957&sxsrf=AOaemvLI2wY8V2D24tRQefM4u4d3auu51Q:1643118363882&q=How+to+enable+GPU+in+Colab&sa=X&ved=2ahUKEwjN85vzhM31AhXXk_0HHZXfBUkQ1QJ6BAg4EAE&biw=1536&bih=696&dpr=1.25) e rendere l'addestramento più veloce.

## Repository già creati
Un esempio può essere già trovato a questo indirizzo https://huggingface.co/Iacopo/Shakespear-GPT2
