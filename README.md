# TextGeneration
Qui c'è la ricetta di base per addestrare un nuovo modello neurale di generazione di testo partendo da testi arbitrari.

## File .ipynb
Il repository contiene un'unico .ipynb file che può essere usato su jupyter notebook oppure (opzione consigliata) su Google Colab.
Seguire il notebook e cambiare unicamente l'assegnazione di input.txt (secondo il testo su cui addestrare il modello) per addestrare e testare il generatore neurale.

## Repository già creati
Un esempio può essere già trovato a questo indirizzo https://huggingface.co/Iacopo/Shakespear-GPT2
